#DAG for tollbooth data for ETL course final

#import block
from datetime import timedelta
from airflow import DAG 
from airflow.operators.bash_operator import BashOperator
from airflow.utils.dates import days_ago

#DAG arguments block 
default_args = {
	'owner':'me',
	'start_date': days_ago(0),
	'email':'me@me.com',
	'email_on_failure': True,
	'email_on_retry': True,
	'retries':1,
	'retry_delay':timedelta(minutes=1)
	}	
    
#Definition and scheduling block
dag=DAG(
    'ETL_toll_data' ,
    schedule_interval=timedelta(days=1),
    default_args=default_args,
    description='Apache Airflow Final Assignment'
)

#Task definition block
unzip_data=BashOperator(
    task_id = 'unzip_data',
    bash_command = 'tar -xvzf /home/project/airflow/dags/finalassignment/tolldata.tgz   -C /home/project/airflow/dags/finalassignment/staging/ ',
    dag = dag
)

extract_data_from_csv=BashOperator(
    task_id = 'extract_data_from_csv',
    bash_command = 'cut -d"," -f1,2,3,4 /home/project/airflow/dags/finalassignment/staging/vehicle-data.csv > /home/project/airflow/dags/finalassignment/staging/csv_data.csv',
    dag = dag
)

extract_data_from_tsv=BashOperator(
    task_id = 'extract_data_from_tsv',
    bash_command = 'cut -f5,6,7 /home/project/airflow/dags/finalassignment/staging/tollplaza-data.tsv | tr -d "\r" | tr "[:blank:]" "," > /home/project/airflow/dags/finalassignment/staging/tsv_data.csv',
    dag = dag
)

extract_data_from_fixed_width=BashOperator(
    task_id = 'extract_data_from_fixed_width',
    bash_command = 'cut -c59-71  /home/project/airflow/dags/finalassignment/staging/payment-data.txt | tr " " "," > /home/project/airflow/dags/finalassignment/staging/fixed_width_data.csv',
    dag = dag
)

consolidate_data=BashOperator(
    task_id = 'consolidate_data',
    bash_command = 'paste -d "," /home/project/airflow/dags/finalassignment/staging/csv_data.csv /home/project/airflow/dags/finalassignment/staging/tsv_data.csv /home/project/airflow/dags/finalassignment/staging/fixed_width_data.csv > /home/project/airflow/dags/finalassignment/staging/extracted_data.csv',
    dag = dag
)

transform_data=BashOperator(
    task_id = 'transform_data',
    bash_command = 'tr "[a-z]" "[A-Z]" < /home/project/airflow/dags/finalassignment/staging/extracted_data.csv > /home/project/airflow/dags/finalassignment/staging/transformed_data.csv',
    dag = dag 
)

#pipeline block
unzip_data>>extract_data_from_csv>>extract_data_from_tsv>>extract_data_from_fixed_width>>consolidate_data>>transform_data
